"""
RTX 3090 Optimized Test Training Script
Ki·ªÉm tra kh·∫£ nƒÉng train tr√™n RTX 3090 24GB VRAM
"""

import torch
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR
from tqdm import tqdm
import os
import time
import psutil
import gc

from model import create_model, PCBLoss
from enhanced_dataset import create_enhanced_dataloaders


def get_gpu_memory_info():
    """L·∫•y th√¥ng tin GPU memory"""
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
        memory_reserved = torch.cuda.memory_reserved() / 1024**3   # GB
        memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
        return memory_allocated, memory_reserved, memory_total
    return 0, 0, 0


def test_rtx3090_training():
    """Test training optimized cho RTX 3090 24GB"""
    
    print("RTX 3090 PCB DEFECT DETECTION - TEST TRAINING")
    print("="*70)
    
    # Ki·ªÉm tra CUDA
    if not torch.cuda.is_available():
        print("‚ùå CUDA kh√¥ng kh·∫£ d·ª•ng! C·∫ßn GPU RTX 3090.")
        return False
    
    print(f"‚úÖ CUDA Version: {torch.version.cuda}")
    print(f"‚úÖ PyTorch Version: {torch.__version__}")
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    
    mem_alloc, mem_reserved, mem_total = get_gpu_memory_info()
    print(f"‚úÖ GPU Memory: {mem_total:.1f}GB total")
    
    # Configuration t·ªëi ∆∞u cho RTX 3090
    config = {
        'data_dir': 'pcb-defect-dataset',
        'batch_size': 16,        # RTX 3090 c√≥ th·ªÉ handle batch l·ªõn
        'num_workers': 8,        # T·ªëi ∆∞u cho CPU multi-core
        'img_size': 600,
        'num_classes': 6,
        'learning_rate': 1e-3,
        'epochs': 5,             # Test 5 epochs
        'pin_memory': True,      # TƒÉng t·ªëc data transfer
        'mixed_precision': True, # S·ª≠ d·ª•ng mixed precision
    }
    
    print(f"\nCONFIGURATION:")
    print(f"   Batch size: {config['batch_size']}")
    print(f"   Num workers: {config['num_workers']}")
    print(f"   Mixed precision: {config['mixed_precision']}")
    print(f"   Pin memory: {config['pin_memory']}")
    
    # Device setup
    device = torch.device('cuda:0')
    print(f"   Device: {device}")
    
    # Clear GPU cache
    torch.cuda.empty_cache()
    gc.collect()
    
    try:
        # Ki·ªÉm tra data loading
        print("\nüìÅ TESTING DATA LOADING...")
        start_time = time.time()
        
        train_loader, val_loader, test_loader = create_enhanced_dataloaders(
            config['data_dir'],
            batch_size=config['batch_size'],
            num_workers=config['num_workers'],
            img_size=config['img_size'],
            pin_memory=config['pin_memory']
        )
        
        data_load_time = time.time() - start_time
        print(f"‚úÖ Data loading successful ({data_load_time:.2f}s)")
        print(f"   Train batches: {len(train_loader)}")
        print(f"   Val batches: {len(val_loader)}")
        print(f"   Test batches: {len(test_loader)}")
        
        # Ki·ªÉm tra model loading
        print("\nü§ñ TESTING MODEL LOADING...")
        start_time = time.time()
        
        model = create_model(num_classes=config['num_classes']).to(device)
        criterion = PCBLoss(num_classes=config['num_classes'])
        optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])
        
        # Mixed precision setup
        scaler = torch.cuda.amp.GradScaler() if config['mixed_precision'] else None
        
        model_load_time = time.time() - start_time
        total_params = sum(p.numel() for p in model.parameters())
        print(f"‚úÖ Model loading successful ({model_load_time:.2f}s)")
        print(f"   Parameters: {total_params:,}")
        print(f"   Model size: ~{total_params * 4 / 1024**2:.1f}MB")
        
        # Check GPU memory after model loading
        mem_alloc, mem_reserved, mem_total = get_gpu_memory_info()
        print(f"   GPU Memory used: {mem_alloc:.1f}GB / {mem_total:.1f}GB")
        
        # Test m·ªôt batch ƒë·∫ßu ti√™n
        print("\nüìä TESTING FIRST BATCH...")
        model.train()
        
        # Test single batch
        test_batch = next(iter(train_loader))
        images, targets, filenames = test_batch
        images = images.to(device, non_blocking=True)
        targets = targets.to(device, non_blocking=True)
        
        print(f"   Batch shape: {images.shape}")
        print(f"   Targets shape: {targets.shape}")
        print(f"   Images range: [{images.min():.3f}, {images.max():.3f}]")
        
        # Forward pass test
        start_time = time.time()
        
        with torch.cuda.amp.autocast(enabled=config['mixed_precision']):
            predictions = model(images)
            loss, loss_dict = criterion(predictions, targets)
        
        forward_time = time.time() - start_time
        print(f"‚úÖ Forward pass successful ({forward_time*1000:.1f}ms)")
        print(f"   Predictions shape: {predictions.shape}")
        print(f"   Loss: {loss.item():.4f}")
        
        # Backward pass test
        start_time = time.time()
        optimizer.zero_grad()
        
        if config['mixed_precision']:
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            loss.backward()
            optimizer.step()
        
        backward_time = time.time() - start_time
        print(f"‚úÖ Backward pass successful ({backward_time*1000:.1f}ms)")
        
        # Memory check after first batch
        mem_alloc, mem_reserved, mem_total = get_gpu_memory_info()
        print(f"   GPU Memory peak: {mem_alloc:.1f}GB / {mem_total:.1f}GB")
        
        # Test training loop
        print(f"\nüöÄ TESTING TRAINING LOOP ({config['epochs']} epochs)...")
        
        for epoch in range(config['epochs']):
            print(f"\n--- Epoch {epoch+1}/{config['epochs']} ---")
            
            model.train()
            epoch_loss = 0
            epoch_coord = 0
            epoch_conf = 0
            epoch_class = 0
            batches_processed = 0
            
            start_time = time.time()
            
            # Ch·ªâ test 5 batches ƒë·∫ßu m·ªói epoch ƒë·ªÉ nhanh
            pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}')
            for batch_idx, (images, targets, filenames) in enumerate(pbar):
                if batch_idx >= 5:  # Ch·ªâ test 5 batches
                    break
                
                images = images.to(device, non_blocking=True)
                targets = targets.to(device, non_blocking=True)
                
                # Forward pass v·ªõi mixed precision
                optimizer.zero_grad()
                
                with torch.cuda.amp.autocast(enabled=config['mixed_precision']):
                    predictions = model(images)
                    loss, loss_dict = criterion(predictions, targets)
                
                # Backward pass
                if config['mixed_precision']:
                    scaler.scale(loss).backward()
                    scaler.step(optimizer)
                    scaler.update()
                else:
                    loss.backward()
                    optimizer.step()
                
                # Track metrics
                epoch_loss += loss.item()
                epoch_coord += float(loss_dict['coord_loss'])
                epoch_conf += float(loss_dict['conf_loss'])
                epoch_class += float(loss_dict['class_loss'])
                batches_processed += 1
                
                # Update progress bar
                pbar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Coord': f'{float(loss_dict["coord_loss"]):.4f}',
                    'Conf': f'{float(loss_dict["conf_loss"]):.4f}',
                    'Class': f'{float(loss_dict["class_loss"]):.4f}',
                    'GPU': f'{torch.cuda.memory_allocated()/1024**3:.1f}GB'
                })
            
            epoch_time = time.time() - start_time
            
            # Calculate averages
            avg_loss = epoch_loss / batches_processed
            avg_coord = epoch_coord / batches_processed
            avg_conf = epoch_conf / batches_processed
            avg_class = epoch_class / batches_processed
            
            print(f"   Epoch time: {epoch_time:.1f}s")
            print(f"   Avg Loss: {avg_loss:.4f}")
            print(f"   Coord Loss: {avg_coord:.4f}")
            print(f"   Conf Loss: {avg_conf:.4f}")
            print(f"   Class Loss: {avg_class:.4f}")
            
            # Check learning progress
            if avg_coord > 0 and avg_class > 0:
                print(f"   ‚úÖ Model is LEARNING! (Non-zero losses)")
            else:
                print(f"   ‚ö†Ô∏è  Warning: Zero coord/class loss detected")
            
            # Memory monitoring
            mem_alloc, mem_reserved, mem_total = get_gpu_memory_info()
            print(f"   GPU Memory: {mem_alloc:.1f}GB / {mem_total:.1f}GB")
            
            # Clear cache between epochs
            torch.cuda.empty_cache()
        
        print("\n" + "="*70)
        print("üéâ RTX 3090 TEST TRAINING - SUMMARY")
        print("="*70)
        print("‚úÖ CUDA v√† PyTorch ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng")
        print("‚úÖ Data loading v·ªõi batch_size=16 th√†nh c√¥ng")
        print("‚úÖ Model loading v√† GPU memory qu·∫£n l√Ω t·ªët")
        print("‚úÖ Mixed precision training ho·∫°t ƒë·ªông")
        print("‚úÖ Forward/backward pass kh√¥ng c√≥ l·ªói")
        print("‚úÖ Training loop ·ªïn ƒë·ªãnh qua nhi·ªÅu epochs")
        print("‚úÖ Loss function t√≠nh to√°n ƒë√∫ng")
        print("‚úÖ Model c√≥ th·ªÉ h·ªçc (non-zero losses)")
        print(f"‚úÖ GPU Memory usage: ~{mem_alloc:.1f}GB / {mem_total:.1f}GB")
        
        # Performance summary
        print(f"\nüìà PERFORMANCE METRICS:")
        print(f"   Forward pass: ~{forward_time*1000:.1f}ms per batch")
        print(f"   Backward pass: ~{backward_time*1000:.1f}ms per batch")
        print(f"   Epoch time: ~{epoch_time:.1f}s (5 batches)")
        print(f"   Estimated full epoch: ~{epoch_time * len(train_loader) / 5:.1f}s")
        
        print(f"\nüöÄ D·ª∞ √ÅN S·∫¥N S√ÄNG CHO RTX 3090!")
        print("   C√≥ th·ªÉ ch·∫°y full training v·ªõi config n√†y.")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå L·ªñI TRAINING: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Cleanup
        torch.cuda.empty_cache()
        gc.collect()


def test_memory_limits():
    """Test memory limits v·ªõi batch sizes kh√°c nhau"""
    print("\nüî¨ TESTING MEMORY LIMITS...")
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA kh√¥ng kh·∫£ d·ª•ng!")
        return
    
    device = torch.device('cuda:0')
    model = create_model(num_classes=6).to(device)
    
    batch_sizes = [8, 16, 24, 32, 40]
    img_size = 600
    
    for batch_size in batch_sizes:
        try:
            torch.cuda.empty_cache()
            
            # Test tensor
            test_input = torch.randn(batch_size, 1, img_size, img_size).to(device)
            
            with torch.no_grad():
                output = model(test_input)
            
            mem_alloc, _, mem_total = get_gpu_memory_info()
            print(f"   Batch {batch_size:2d}: ‚úÖ {mem_alloc:.1f}GB / {mem_total:.1f}GB")
            
            del test_input, output
            
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"   Batch {batch_size:2d}: ‚ùå OOM")
                break
            else:
                raise e
    
    torch.cuda.empty_cache()


if __name__ == "__main__":
    print("KI·ªÇM TRA RTX 3090 TRAINING READINESS")
    print("=" * 50)
    
    # Test basic training
    success = test_rtx3090_training()
    
    if success:
        # Test memory limits
        test_memory_limits()
        
        print("\nüèÅ K·∫æT LU·∫¨N:")
        print("‚úÖ D·ª± √°n ho√†n to√†n s·∫µn s√†ng cho RTX 3090")
        print("‚úÖ Ch·ªâ c·∫ßn ch·∫°y: pip install -r requirements.txt")
        print("‚úÖ Sau ƒë√≥ ch·∫°y: python train.py")
    else:
        print("\n‚ùå C·∫ßn ki·ªÉm tra l·∫°i setup")